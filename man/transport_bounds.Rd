% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/transport.R
\name{transport_bounds}
\alias{transport_bounds}
\title{Estimate non-overlap bounds for the Transported Average Treatment Effect}
\usage{
transport_bounds(
  data,
  X,
  S,
  A,
  Y,
  learners_trt = c("SL.glm"),
  learners_source = c("SL.glm"),
  learners_outcome = c("SL.glm"),
  thresholds = c(10^seq(-4, -1, 0.05)),
  smoothness = 0.01,
  alpha = 0.05,
  outer_folds = 5,
  inner_folds = 5,
  bootstrap = TRUE,
  bootstrap_draws = 1000,
  nuisance = NULL
)
}
\arguments{
\item{data}{data frame containing data estimating transport effect bounds}

\item{X}{vector of covariate column names}

\item{S}{name of column containing binary source indicator}

\item{A}{name of column containing binary treatment indicator}

\item{Y}{name of column containing outcome variable (bounded between zero and one)}

\item{learners_trt}{SuperLearner learners for estimating propensity
score model.}

\item{learners_source}{SuperLearner learners for estimating source model}

\item{learners_outcome}{SuperLearner learners for estimtaing outcome
model.}

\item{thresholds}{vector of propensity score thresholds}

\item{smoothness}{tuning parameter controlling smoothness of the indicator
unction approximations (smaller values imply a less smooth approximation)}

\item{alpha}{significance level of pointwise and
uniform confidence intervals (default 5\%)}

\item{outer_folds}{Number of folds in outer cross-fitting loop}

\item{inner_folds}{Number of folds used by SuperLearner within
each outer cross-fitting loop}

\item{bootstrap}{whether to use multiplier bootstrap to compute
uniform confidence sets}

\item{bootstrap_draws}{number of multiplier bootstrap draws}

\item{nuisance}{list containing estimated nuisance parameters (optional)}
}
\value{
A list of class \code{atebounds} containing the following elements:
\describe{
\item{bounds}{List containing estimated bounds for each smoothness parameter.}
\item{smoothness}{Vector of smoothness parameters.}
\item{thresholds}{Vector of propensity score thresholds.}
\item{onestep}{Doubly-robust one-step point estimate and confidence interval for ATE.}
\item{alpha}{Significance level.}
\item{N}{Number of observations.}
\item{K}{Number of propensity score thresholds.}
\item{nuisance}{propensity score and conditional mean outcome predictions.}
}
}
\description{
Estimate non-overlap bounds for the Transported Average Treatment Effect
}
\details{
This function estimates non-overlap bounds for the transport effect on a
user-specified grid of propensity score thresholds and smoothness
tuning parameter values.

The basic idea of non-overlap bounds is to divide the population into
two parts: a subpopulation in which overlap is satisfied, and a subpopulation
in which overlap is violated. The propensity score thresholds defines how the
division is done: all units with estimated propensity score below the
threshold are considered to be in the non-overlap subpopulation, and the rest
of the units are considered to be in the overlap subpopulation.

A-priori, we don't typically know what propensity score threshold will lead
to the tightest bounds on the ATE. Therefore, we try a range of values
(using the \code{threshold} argument), and the function uses a multiplier
bootstrap technique to form a uniform confidence set. You can configure the
multiplier bootstrap through the \code{bootstrap_draws}
argument, which sets how many bootstrap replications to use.

By default, 95\% uniform confidence sets are formed. You can configure the
significance level with the \code{alpha} argument; the uniform confidence
sets are designed to be valid with probability \eqn{(1 - \alpha) \times 100\%}.

The propensity scores and outcome regression models needed to estimate the
bounds can be estimated using any method, including logistic regressions or
flexible machine-learning algorithms. To control overfitting, we use
sample-splitting methods. There is an outer layer of cross-fitting,
in which the sample is split into folds (you can set how many using the
\code{outer_folds} argument), models are fit on the training sample for each
fold, and propensity scores and conditional mean outcomes are predicted on
the validation sample. Within each of these outer folds, \code{SuperLearner}
is used to form an ensemble of learners to optimally predict the propensity
scores and conditional mean outcomes. \code{SuperLearner} itself uses
cross-validation to estimate the performance of each learner, and you can
configure the number of cross-validation folds using the \code{inner_folds}
argument.

You can use the function \code{SuperLearner::listWrappers} for a list of the
algorithms available for inclusion in the \code{learners_trt} and
\code{learners_outcome} arguments.

An important tuning parameter is the \code{smoothness} argument, which
controls the smoothness of an inner approximation of certain indicator
functions that arise in the definition of the non-overlap bounds. In practice,
a small value (like \code{10e-2}) can typically be used. We
recommend trying several small values, like \code{10e-3}, \code{10e-2},
and \code{10e-1} in a sensitivity analysis.
}
\examples{
dat <- simulate_transport_example(
  seed = 1,
  N = 5e2,
  alpha = 3,
  beta = 0.1,
  gamma = 1
)

bounds <- transport_bounds(
  dat,
  X = c("X1", "X2"), S = "S", A = "A", Y = "Y",
  thresholds = c(10^seq(-3, -0.5, 0.1)),
  smoothness = c(0.005)
)

}
\seealso{
\link{summary.transportbounds}

\link{plot.transportbounds}
}
